
@article{naskar_deepfake_2024,
	title = {Deepfake detection using deep feature stacking and meta-learning},
	volume = {10},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {2405-8440},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2405844024019649},
	doi = {10.1016/j.heliyon.2024.e25933},
	language = {en},
	number = {4},
	urldate = {2025-07-09},
	journal = {Heliyon},
	author = {Naskar, Gourab and Mohiuddin, Sk and Malakar, Samir and Cuevas, Erik and Sarkar, Ram},
	month = feb,
	year = {2024},
	note = {Publisher: Elsevier BV},
	pages = {e25933},
	file = {PDF:files/78/Naskar et al. - 2024 - Deepfake detection using deep feature stacking and meta-learning.pdf:application/pdf},
}

@article{aissms_institute_of_information_technology_pune_pune_maharashtra_india_deepfake_2024,
	title = {{DeepFake} {Image} {Detection}},
	volume = {08},
	issn = {2582-3930},
	url = {https://ijsrem.com/download/deepfake-image-detection/},
	doi = {10.55041/ijsrem30215},
	abstract = {The growth of deepfakes in today’s digital environment raises significant doubts regarding the genuineness and dependability of the content found. To overcome this new challenge, Developing an effective method in the context of detection of deep images. In this study, we conduct a comparative analysis of three varied convolutional neural networks (CNNs) for deepfake image detection. Our experimental results highlight the strengths and weaknesses of each CNN architecture.},
	language = {en},
	number = {04},
	urldate = {2025-07-09},
	journal = {IJSREM},
	author = {{AISSMS Institute of Information Technology, Pune Pune, Maharashtra, India} and S, Mrs. Prajwal},
	month = apr,
	year = {2024},
	note = {Publisher: Indospace Publications},
	pages = {1--5},
	file = {PDF:files/79/AISSMS Institute of Information Technology, Pune Pune, Maharashtra, India and S - 2024 - DeepFake Image Detection.pdf:application/pdf},
}

@article{dept_of_computer_science_and_engineering_universal_engineering_college_review_2024,
	title = {A {Review} on {Deepfake} {Detection}},
	volume = {08},
	issn = {2582-3930},
	url = {https://ijsrem.com/download/a-review-on-deepfake-detection/},
	doi = {10.55041/ijsrem29735},
	abstract = {Deepfake video detection is a new field in artificial intelligence (AI) and computer vision. Its main objective is to detect deepfake videos, which are digitally altered footage in which the original video is replaced with that of another person. "Deepfake video detection" is the process of recognizing and labelling videos that have been created by altering or substituting the appearance and actions of persons in the video through the use of deep learning techniques. These techniques are often used to create extremely realistic fake videos that can be used for deceptive purposes, such as spreading false information or assuming the identity of another individual. Deepfake videos are distinguished from real ones by examining patterns in the video footage and looking for differences in facial expressions. Our initiative is to protect the legitimacy of visual media in the digital age by making a substantial contribution to the fight against the proliferation and misuse of deepfake materials. The goal of the research is to create a deep learning-based method for identifying deepfake videos. Our system can differentiate between real and fake information by using deep learning techniques and a variety of datasets for training, which helps combat the proliferation of false visual media. Conclusively, our effort on deep learning-based deepfake video identification is an essential step towards tackling the escalating danger of digital manipulation.},
	language = {en},
	number = {03},
	urldate = {2025-07-09},
	journal = {IJSREM},
	author = {{Dept. of Computer Science and Engineering, Universal Engineering College} and Ajith, Adithya},
	month = mar,
	year = {2024},
	note = {Publisher: Indospace Publications},
	pages = {1--5},
	file = {PDF:files/80/Dept. of Computer Science and Engineering, Universal Engineering College and Ajith - 2024 - A Review on Deepfake Detection.pdf:application/pdf},
}

@article{a_sathiya_priya_cnn_2024,
	title = {{CNN} and {RNN} using {Deepfake} detection},
	volume = {11},
	issn = {2582-8185},
	url = {https://ijsra.net/content/cnn-and-rnn-using-deepfake-detection},
	doi = {10.30574/ijsra.2024.11.2.0460},
	abstract = {Deep fake Detection is the task of detecting the fake images that have been generated using deep learning techniques. Deep fakes are created by using machine learning algorithms to manipulate or replace parts of an original video or image, such as the face of a person. The goal of deep fake detection is to identify such manipulations and distinguish them from real videos or images. Deep fake technology has emerged as a significant concern in recent years, presenting challenges in various fields, including media authenticity, privacy, and security.},
	language = {en},
	number = {2},
	urldate = {2025-07-09},
	journal = {Int. J. Sci. Res. Arch.},
	author = {{A. Sathiya Priya} and {T. Manisha}},
	month = mar,
	year = {2024},
	note = {Publisher: GSC Online Press},
	pages = {613--618},
	file = {PDF:files/81/A. Sathiya Priya and T. Manisha - 2024 - CNN and RNN using Deepfake detection.pdf:application/pdf},
}

@article{department_of_computer_science_and_engineering_malnad_college_of_engineering_hassan_deep_2024,
	title = {Deep {Fake} {Detection} {System}},
	volume = {08},
	issn = {2582-3930},
	url = {https://ijsrem.com/download/deep-fake-detection-system/},
	doi = {10.55041/ijsrem31014},
	abstract = {Deep learning methods are used by the Deep Fake Detection System to recognize "deepfakes," or distorted media content. Deepfakes are artificial media produced by sophisticated artificial intelligence algorithms that threaten the credibility of media. The goal of our project is to create a reliable system that can discriminate between authentic and modified content in order to stop the spread of false information and protect media integrity. Our goal is to improve deepfake detection efficiency and accuracy by conducting a thorough evaluation of deep learning-based detection techniques. Our technology aims to offer real-time detection capabilities by utilizing sophisticated neural networks and machine learning techniques. This will aid in the continuous endeavors to tackle the widespread occurrence of deepfakes in digital media.},
	language = {en},
	number = {04},
	urldate = {2025-07-09},
	journal = {IJSREM},
	author = {{Department Of Computer Science and Engineering, Malnad College Of Engineering, Hassan} and D P, Gurukiran},
	month = apr,
	year = {2024},
	note = {Publisher: Indospace Publications},
	pages = {1--5},
	file = {PDF:files/82/Department Of Computer Science and Engineering, Malnad College Of Engineering, Hassan and D P - 2024 - Deep Fake Detection System.pdf:application/pdf},
}

@article{patil_deepfake_2024,
	title = {Deepfake {Detection} {System}},
	volume = {12},
	issn = {2321-9653},
	url = {https://www.ijraset.com/best-journal/deepfake-detection-system-240},
	doi = {10.22214/ijraset.2024.61211},
	abstract = {The emergence of deepfake technology presents a profound challenge to the integrity and trustworthiness of multimedia content online. To address this issue, this study proposes a novel deepfake detection system that integrates a hybrid Recurrent Neural Network (RNN), Convolutional Neural Network (CNN), and Long Short-Term Memory (LSTM) architecture. The proposed system employs a multi-faceted approach to training by utilizing several diverse datasets encompassing real and synthetic videos. This comprehensive training strategy ensures that the model learns robust features representative of both authentic and manipulated content across various contexts and scenarios. By incorporating a range of datasets, including those specifically curated to represent different deepfake generation techniques and quality levels, the model gains a more comprehensive understanding of the intricate nuances present in manipulated videos. During the training phase, the CNN component extracts high-level spatial features from individual frames of the input videos, effectively capturing visual patterns indicative of deepfake manipulation. Subsequently, the LSTM network models the temporal dynamics inherent in video sequences, enabling the detection of subtle inconsistencies over time. Additionally, the RNN component facilitates the capture of contextual dependencies across sequential frames, further enhancing the model’s discriminative capabilities. Extensive experimentation is conducted to evaluate the proposed approach, encompassing benchmark datasets as well as additional datasets curated to represent a wide range of deepfake manipulation scenarios. The results demonstrate the superior performance of the hybrid RNN-LSTM architecture compared to state-of-the-art deepfake detection techniques, particularly in terms of accuracy, robustness, and generalization across diverse datasets. In conclusion, the proposed deepfake detection framework offers a powerful and reliable solution to mitigate the proliferation of fake multimedia content online. By leveraging multiple datasets during training, the model achieves heightened sensitivity to the subtle cues indicative of deepfake manipulation, thereby safeguarding the integrity and credibility of digital media platforms.},
	language = {en},
	number = {4},
	urldate = {2025-07-09},
	journal = {IJRASET},
	author = {Patil, Pragati},
	month = apr,
	year = {2024},
	note = {Publisher: International Journal for Research in Applied Science and Engineering Technology (IJRASET)},
	pages = {5271--5277},
	file = {PDF:files/83/Patil - 2024 - Deepfake Detection System.pdf:application/pdf},
}

@article{kocak_deepfake_2024,
	title = {Deepfake {Video} {Detection} {Using} {Convolutional} {Neural} {Network} {Based} {Hybrid} {Approach}},
	issn = {2147-9429},
	url = {http://dergipark.org.tr/en/doi/10.2339/politeknik.1523983},
	doi = {10.2339/politeknik.1523983},
	abstract = {Given the rapid advancement of deepfake technology, which allows for the creation of highly realistic fake content, there is a pressing need for an efficient solution to address the security risks associated with this technology. Deepfake videos are widely recognized for their significant implications, including the potential for identity theft, the dissemination of false information, and the endangerment of national security. Therefore, it is crucial to develop and enhance the reliability of deepfake detection algorithms. In this study, feature extraction techniques were performed to utilize deep learning algorithms such as Xception and ResNet50 to detect deepfakes in a video dataset using the DFDC dataset. Additionally, a total of eight hybrid models were developed using various classification algorithms such as SVM, KNN, MLP, and RF. The ResNet50 and RF hybrid models achieved the highest accuracy rate of 98\%, with an AUC value of 99.65\%. This study presents a machine learning method that has been developed to address different technical challenges in the field of deepfake detection and effectively identify deepfakes. The proposed method has demonstrated successful performance compared to state-of-the-art models, proving its effectiveness in accurately detecting fake content within videos.},
	language = {en},
	urldate = {2025-07-09},
	journal = {Politeknik Dergisi},
	author = {Koçak, Aynur and Alkan, Mustafa and Arıkan, Süleyman Muhammed},
	month = nov,
	year = {2024},
	note = {Publisher: Politeknik Dergisi},
	pages = {1--1},
	file = {PDF:files/86/Koçak et al. - 2024 - Deepfake Video Detection Using Convolutional Neural Network Based Hybrid Approach.pdf:application/pdf},
}

@article{gandhi_multimodal_2024,
	title = {A {Multimodal} {Framework} for {Deepfake} {Detection}},
	url = {http://arxiv.org/abs/2410.03487},
	doi = {10.53555/jes.v20i10s.6126},
	abstract = {The rapid advancement of deepfake technology poses a significant threat to digital media integrity. Deepfakes, synthetic media created using AI, can convincingly alter videos and audio to misrepresent reality. This creates risks of misinformation, fraud, and severe implications for personal privacy and security. Our research addresses the critical issue of deepfakes through an innovative multimodal approach, targeting both visual and auditory elements. This comprehensive strategy recognizes that human perception integrates multiple sensory inputs, particularly visual and auditory information, to form a complete understanding of media content. For visual analysis, a model that employs advanced feature extraction techniques was developed, extracting nine distinct facial characteristics and then applying various machine learning and deep learning models. For auditory analysis, our model leverages mel-spectrogram analysis for feature extraction and then applies various machine learning and deep learning models. To achieve a combined analysis, real and deepfake audio in the original dataset were swapped for testing purposes and ensured balanced samples. Using our proposed models for video and audio classification i.e. Artificial Neural Network and VGG19, the overall sample is classified as deepfake if either component is identified as such. Our multimodal framework combines visual and auditory analyses, yielding an accuracy of 94\%.},
	language = {en},
	urldate = {2025-07-09},
	journal = {jes},
	author = {Gandhi, Kashish and Kulkarni, Prutha and Shah, Taran and Chaudhari, Piyush and Narvekar, Meera and Ghag, Kranti},
	month = aug,
	year = {2024},
	note = {arXiv:2410.03487 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Logic in Computer Science, Computer Science - Machine Learning},
	annote = {Comment: 22 pages, 14 figures, Accepted in Journal of Electrical Systems},
	file = {PDF:files/88/Gandhi et al. - 2024 - A Multimodal Framework for Deepfake Detection.pdf:application/pdf},
}

@inproceedings{ghita_deepfake_2024,
	address = {Tbilisi, Georgia},
	title = {Deepfake {Image} {Detection} {Using} {Vision} {Transformer} {Models}},
	copyright = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/10646310/},
	doi = {10.1109/blackseacom61746.2024.10646310},
	abstract = {Deepfake images are causing an increasing negative impact on the day to day life and pose significant challenges for the society. There are various categories of deepfake images as the technology evolves and becomes more accessible. In parallel, deepfake detection methods are also improving, from basic features analysis to pairwise analysis and deep learning; nevertheless, to date, there is no consistent method able to fully detect such images. This study aims to provide an overview of existing methods of deepfake detection in the literature and investigate the accuracy of models based on Vision Transformer (VIT) when analysing and detecting deepfake images. We implement a VIT model-based deepfake detection technique, which is trained and tasted on a mixed real and deepfake images dataset from Kaggle, containing 40000 images.},
	language = {en},
	urldate = {2025-07-09},
	booktitle = {2024 {IEEE} {International} {Black} {Sea} {Conference} on {Communications} and {Networking} ({BlackSeaCom})},
	publisher = {IEEE},
	author = {Ghita, Bogdan and Kuzminykh, Ievgeniia and Usama, Abubakar and Bakhshi, Taimur and Marchang, Jims},
	month = jun,
	year = {2024},
	pages = {332--335},
	file = {PDF:files/90/Ghita et al. - 2024 - Deepfake Image Detection Using Vision Transformer Models.pdf:application/pdf},
}

@misc{astrid_targeted_2024,
	title = {Targeted {Augmented} {Data} for {Audio} {Deepfake} {Detection}},
	url = {http://arxiv.org/abs/2407.07598},
	doi = {10.48550/arXiv.2407.07598},
	abstract = {The availability of highly convincing audio deepfake generators highlights the need for designing robust audio deepfake detectors. Existing works often rely solely on real and fake data available in the training set, which may lead to overfitting, thereby reducing the robustness to unseen manipulations. To enhance the generalization capabilities of audio deepfake detectors, we propose a novel augmentation method for generating audio pseudo-fakes targeting the decision boundary of the model. Inspired by adversarial attacks, we perturb original real data to synthesize pseudo-fakes with ambiguous prediction probabilities. Comprehensive experiments on two well-known architectures demonstrate that the proposed augmentation contributes to improving the generalization capabilities of these architectures.},
	language = {en},
	urldate = {2025-07-09},
	publisher = {arXiv},
	author = {Astrid, Marcella and Ghorbel, Enjie and Aouada, Djamila},
	month = jul,
	year = {2024},
	note = {arXiv:2407.07598 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Sound, Electrical Engineering and Systems Science - Audio and Speech Processing},
	annote = {Comment: Accepted in EUSIPCO 2024},
	file = {PDF:files/91/Astrid et al. - 2024 - Targeted Augmented Data for Audio Deepfake Detection.pdf:application/pdf},
}

@inproceedings{deressa_improved_2024,
	address = {Turin, Italy},
	title = {Improved {Deepfake} {Video} {Detection} {Using} {Convolutional} {Vision} {Transformer}},
	copyright = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/10585593/},
	doi = {10.1109/gem61861.2024.10585593},
	abstract = {Deepfakes are hyper-realistic videos in which the faces are replaced, swapped, or forged using deep-learning models. This potent media manipulation techniques hold promise for applications across various domains. Yet, they also present a significant risk when employed for malicious intents like identity fraud, phishing, spreading false information, and executing scams. In this work, we propose a novel and improved Deepfake video detector that uses a Convolutional Vision Transformer (CViT2), which builds on the concepts of our previous work (CViT). The CViT architecture consists of two components: a Convolutional Neural Network that extracts learnable features, and a Vision Transformer that categorizes these learned features using an attention mechanism. We trained and evaluted our model on 5 datasets, namely Deepfake Detection Challenge Dataset (DFDC), FaceForensics++ (FF++), Celeb-DF v2, DeepfakeTIMIT, and TrustedMedia. On the test sets unseen during training, we achieved an accuracy of 95\%, 94.8\%, 98.3\% and 76.7\% on the DFDC, FF++, Celeb-DF v2, and TIMIT datasets, respectively. In conclusion, our proposed Deepfake detector can be used in the battle against misinformation and other forensic use cases.},
	language = {en},
	urldate = {2025-07-09},
	booktitle = {2024 {IEEE} {Gaming}, {Entertainment}, and {Media} {Conference} ({GEM})},
	publisher = {IEEE},
	author = {Deressa, Deressa Wodajo and Lambert, Peter and Van Wallendael, Glenn and Atnafu, Solomon and Mareen, Hannes},
	month = jun,
	year = {2024},
	pages = {1--6},
	file = {PDF:files/94/Deressa et al. - 2024 - Improved Deepfake Video Detection Using Convolutional Vision Transformer.pdf:application/pdf},
}

@inproceedings{nailwal_deepfake_2023,
	address = {Chennai, India},
	title = {Deepfake {Detection}: {A} {Multi}-{Algorithmic} and {Multi}-{Modal} {Approach} for {Robust} {Detection} and {Analysis}},
	copyright = {https://doi.org/10.15223/policy-029},
	shorttitle = {Deepfake {Detection}},
	url = {https://ieeexplore.ieee.org/document/10369155/},
	doi = {10.1109/rmkmate59243.2023.10369155},
	abstract = {In a time when deepfakes are eroding the reliability of digital media, our innovative research introduces a multi-faceted framework that achieves unprecedented levels of detection accuracy. Boasting a 97\% success rate in verifying visual content and an almost unblemished 98.5\% in audio analysis, our system serves as a formidable barrier against the malicious alteration of digital assets. Central to our model's stellar performance is the seamless integration of convolutional neural networks (CNNs) with ReLU activation mechanisms, all fine-tuned via stochastic gradient descent (SGD). This expertly engineered architecture is highly proficient at analyzing the nuanced spatial features of visual media, and it works in synergy with cutting-edge machine learning algorithms. For the audio detection aspect, we employ random forest algorithms, celebrated for their robustness and versatility. This ensemble learning approach adds an extra layer of complexity to the model, effectively identifying the intricate spectral and temporal characteristics of audio streams, thereby boosting the overall efficacy of our detection system. Our methodology is further fortified by meticulous data preprocessing methods, such as normalization and data augmentation, which ensure the model's robustness against a myriad of deepfake techniques. This groundbreaking research not only establishes a new benchmark in the arena of deepfake detection but also has significant ramifications for the wider field of cybersecurity and the preservation of digital authenticity. With its unmatched performance metrics, our research represents a pivotal advancement in combating the growing menace of deepfakes in today's digital society.},
	language = {en},
	urldate = {2025-07-09},
	booktitle = {2023 {International} {Conference} on {Research} {Methodologies} in {Knowledge} {Management}, {Artificial} {Intelligence} and {Telecommunication} {Engineering} ({RMKMATE})},
	publisher = {IEEE},
	author = {Nailwal, Sagar and Singhal, Saksham and Singh, Nongmeikapam Thoiba and Raza, Arbaz},
	month = nov,
	year = {2023},
	pages = {1--8},
	file = {PDF:files/97/Nailwal et al. - 2023 - Deepfake Detection A Multi-Algorithmic and Multi-Modal Approach for Robust Detection and Analysis.pdf:application/pdf},
}

@inproceedings{rana_deepfake_2023,
	address = {Charlotte NC USA},
	title = {Deepfake {Detection}: {A} {Tutorial}},
	copyright = {https://www.acm.org/publications/policies/copyright\_policy\#Background},
	shorttitle = {Deepfake {Detection}},
	url = {https://dl.acm.org/doi/10.1145/3579987.3586562},
	doi = {10.1145/3579987.3586562},
	abstract = {This tutorial presents developments on the detection of Deepfakes, which are realistic images, audios and videos created using deep learning techniques. Deepfakes can be readily used for malicious purposes and pose a serious threat to privacy and security. The tutorial summarizes recent Deepfake detection techniques and evaluates their effectiveness with respect to several benchmark datasets. Our study finds that no single method can reliably detect all Deepfakes and, therefore, combining multiple methods is often necessary to achieve high detection rates. The study also suggests that more extensive and diverse datasets are needed to improve the accuracy of detection algorithms. A taxonomy of Deepfake detection techniques is introduced to aid future research and development in the field. We conclude by calling for the development of more effective Deepfake detection methods and countermeasures to combat this evolving and spreading threat.},
	language = {en},
	urldate = {2025-07-09},
	booktitle = {Proceedings of the 9th {ACM} {International} {Workshop} on {Security} and {Privacy} {Analytics}},
	publisher = {ACM},
	author = {Rana, Md Shohel and Sung, Andrew H.},
	month = apr,
	year = {2023},
	pages = {55--56},
	file = {PDF:files/99/Rana and Sung - 2023 - Deepfake Detection A Tutorial.pdf:application/pdf},
}

@misc{muppalla_integrating_2023,
	title = {Integrating {Audio}-{Visual} {Features} for {Multimodal} {Deepfake} {Detection}},
	url = {http://arxiv.org/abs/2310.03827},
	doi = {10.48550/arXiv.2310.03827},
	abstract = {Deepfakes are AI-generated media in which an image or video has been digitally modified. The advancements made in deepfake technology have led to privacy and security issues. Most deepfake detection techniques rely on the detection of a single modality. Existing methods for audio-visual detection do not always surpass that of the analysis based on single modalities. Therefore, this paper proposes an audiovisual-based method for deepfake detection, which integrates fine-grained deepfake identification with binary classification. We categorize the samples into four types by combining labels specific to each single modality. This method enhances the detection under intra-domain and cross-domain testing.},
	language = {en},
	urldate = {2025-07-09},
	publisher = {arXiv},
	author = {Muppalla, Sneha and Jia, Shan and Lyu, Siwei},
	month = oct,
	year = {2023},
	note = {arXiv:2310.03827 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {PDF:files/100/Muppalla et al. - 2023 - Integrating Audio-Visual Features for Multimodal Deepfake Detection.pdf:application/pdf},
}

@inproceedings{albazony_deepfake_2023,
	address = {Al-Muthana, Iraq},
	title = {{DeepFake} {Videos} {Detection} by {Using} {Recurrent} {Neural} {Network} ({RNN})},
	copyright = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/10217956/},
	doi = {10.1109/aiccit57614.2023.10217956},
	abstract = {In the last few years, the increasing development of various tools to make fake videos from real videos has been raised. Thus, several models/approaches have been constructed to detect and reveals fake video. Consequently, this research is conducted to propose a new model based on combining Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), and image preprocessing techniques to classify and find the fake video from the real video. To implement and evaluate the proposed model, a MATLAB simulator has been used. The deepFake Images dataset is used for evaluations. This dataset contains 135 real videos as well as 677 fake videos created using different tools on real videos. Two scenarios have been utilized to evaluate the performance of the proposed model which are; dimensions of the training data and different sizes of the training data. The results show that the proposed model has been able to provide better results than the previous model.},
	language = {en},
	urldate = {2025-07-09},
	booktitle = {2023 {Al}-{Sadiq} {International} {Conference} on {Communication} and {Information} {Technology} ({AICCIT})},
	publisher = {IEEE},
	author = {Albazony, Ali Abdulzahra Mohsin and Al-Wzwazy, Haider A and Al-Khaleefa, Ahmed Salih and Alazzawi, Murtadha A. and Almohamadi, Mohammed and Alavi, Seyed Enayatallah},
	month = jul,
	year = {2023},
	pages = {103--107},
	file = {PDF:files/105/Albazony et al. - 2023 - DeepFake Videos Detection by Using Recurrent Neural Network (RNN).pdf:application/pdf},
}

@article{al_dulaimi_deepfake_2023,
	title = {Deepfake {Detection} {Model} {Based} on {Combined} {Features} {Extracted} from {Facenet} and {PCA} {Techniques}},
	volume = {17},
	issn = {2311-7990},
	url = {https://csmj.mosuljournals.com/article_181628.html},
	doi = {10.33899/csmj.2023.181628},
	language = {en},
	number = {2},
	urldate = {2025-07-09},
	journal = {AL-Rafidain Journal of Computer Sciences and Mathematics},
	author = {Al\_Dulaimi, Duha Amir and Ibrahim, Laheeb},
	month = dec,
	year = {2023},
	note = {Publisher: University of Mosul},
	pages = {19--27},
	file = {PDF:files/106/Al_Dulaimi and Ibrahim - 2023 - Deepfake Detection Model Based on Combined Features Extracted from Facenet and PCA Techniques.pdf:application/pdf},
}

@article{malik_deepfake_2022,
	title = {{DeepFake} {Detection} for {Human} {Face} {Images} and {Videos}: {A} {Survey}},
	volume = {10},
	copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {2169-3536},
	shorttitle = {{DeepFake} {Detection} for {Human} {Face} {Images} and {Videos}},
	url = {https://ieeexplore.ieee.org/document/9712265/},
	doi = {10.1109/access.2022.3151186},
	abstract = {Techniques for creating and manipulating multimedia information have progressed to the point where they can now ensure a high degree of realism. DeepFake is a generative deep learning algorithm that creates or modiﬁes face features in a superrealistic form, in which it is difﬁcult to distinguish between real and fake features. This technology has greatly advanced and promotes a wide range of applications in TV channels, video game industries, and cinema, such as improving visual effects in movies, as well as a variety of criminal activities, such as misinformation generation by mimicking famous people. To identify and classify DeepFakes, research in DeepFake detection using deep neural networks (DNNs) has attracted increased interest. Basically, DeepFake is the regenerated media that is obtained by injecting or replacing some information within the DNN model. In this survey, we will summarize the DeepFake detection methods in face images and videos on the basis of their results, performance, methodology used and detection type. We will review the existing types of DeepFake creation techniques and sort them into ﬁve major categories. Generally, DeepFake models are trained on DeepFake datasets and tested with experiments. Moreover, we will summarize the available DeepFake dataset trends, focusing on their improvements. Additionally, the issue of how DeepFake detection aims to generate a generalized DeepFake detection model will be analyzed. Finally, the challenges related to DeepFake creation and detection will be discussed. We hope that the knowledge encompassed in this survey will accelerate the use of deep learning in face image and video DeepFake detection methods.},
	language = {en},
	urldate = {2025-07-09},
	journal = {IEEE Access},
	author = {Malik, Asad and Kuribayashi, Minoru and Abdullahi, Sani M. and Khan, Ahmad Neyaz},
	year = {2022},
	note = {Publisher: Institute of Electrical and Electronics Engineers (IEEE)},
	pages = {18757--18775},
	file = {PDF:files/107/Malik et al. - 2022 - DeepFake Detection for Human Face Images and Videos A Survey.pdf:application/pdf},
}

@article{ge_deepfake_2022,
	title = {Deepfake {Video} {Detection} via {Predictive} {Representation} {Learning}},
	volume = {18},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1551-6857, 1551-6865},
	url = {https://dl.acm.org/doi/10.1145/3536426},
	doi = {10.1145/3536426},
	abstract = {Increasingly advanced deepfake approaches have made the detection of deepfake videos very challenging. We observe that the general deepfake videos often exhibit appearance-level temporal inconsistencies in some facial components between frames, resulting in discriminative spatiotemporal latent patterns among semantic-level feature maps. Inspired by this finding, we propose a predictive representative learning approach termed Latent Pattern Sensing to capture these semantic change characteristics for deepfake video detection. The approach cascades a Convolution Neural Network-based encoder, a ConvGRU-based aggregator, and a single-layer binary classifier. The encoder and aggregator are pretrained in a self-supervised manner to form the representative spatiotemporal context features. Then, the classifier is trained to classify the context features, distinguishing fake videos from real ones. Finally, we propose a selective self-distillation fine-tuning method to further improve the robustness and performance of the detector. In this manner, the extracted features can simultaneously describe the latent patterns of videos across frames spatially and temporally in a unified way, leading to an effective and robust deepfake video detector. Extensive experiments and comprehensive analysis prove the effectiveness of our approach, e.g., achieving a very highest Area Under Curve (AUC) score of 99.94\% on FaceForensics++ benchmark and surpassing 12 states of the art at least 7.90\%@AUC and 8.69\%@AUC on challenging DFDC and Celeb-DF(v2) benchmarks, respectively.},
	language = {en},
	number = {2s},
	urldate = {2025-07-09},
	journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
	author = {Ge, Shiming and Lin, Fanzhao and Li, Chenyu and Zhang, Daichi and Wang, Weiping and Zeng, Dan},
	month = jun,
	year = {2022},
	note = {Publisher: Association for Computing Machinery (ACM)},
	pages = {1--21},
	file = {PDF:files/110/Ge et al. - 2022 - Deepfake Video Detection via Predictive Representation Learning.pdf:application/pdf},
}

@article{rana_deepfake_2022,
	title = {Deepfake {Detection}: {A} {Systematic} {Literature} {Review}},
	volume = {10},
	copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {2169-3536},
	shorttitle = {Deepfake {Detection}},
	url = {https://ieeexplore.ieee.org/document/9721302/},
	doi = {10.1109/access.2022.3154404},
	abstract = {Over the last few decades, rapid progress in AI, machine learning, and deep learning has resulted in new techniques and various tools for manipulating multimedia. Though the technology has been mostly used in legitimate applications such as for entertainment and education, etc., malicious users have also exploited them for unlawful or nefarious purposes. For example, high-quality and realistic fake videos, images, or audios have been created to spread misinformation and propaganda, foment political discord and hate, or even harass and blackmail people. The manipulated, high-quality and realistic videos have become known recently as Deepfake. Various approaches have since been described in the literature to deal with the problems raised by Deepfake. To provide an updated overview of the research works in Deepfake detection, we conduct a systematic literature review (SLR) in this paper, summarizing 112 relevant articles from 2018 to 2020 that presented a variety of methodologies. We analyze them by grouping them into four different categories: deep learning-based techniques, classical machine learning-based methods, statistical techniques, and blockchain-based techniques. We also evaluate the performance of the detection capability of the various methods with respect to different datasets and conclude that the deep learning-based methods outperform other methods in Deepfake detection.},
	language = {en},
	urldate = {2025-07-09},
	journal = {IEEE Access},
	author = {Rana, Md Shohel and Nobi, Mohammad Nur and Murali, Beddhu and Sung, Andrew H.},
	year = {2022},
	note = {Publisher: Institute of Electrical and Electronics Engineers (IEEE)},
	pages = {25494--25513},
	file = {PDF:files/113/Rana et al. - 2022 - Deepfake Detection A Systematic Literature Review.pdf:application/pdf},
}

@inproceedings{trabelsi_improving_2022,
	address = {Belgrade, Serbia},
	title = {Improving {Deepfake} {Detection} by {Mixing} {Top} {Solutions} of the {DFDC}},
	copyright = {https://doi.org/10.15223/policy-029},
	url = {https://ieeexplore.ieee.org/document/9909905/},
	doi = {10.23919/eusipco55093.2022.9909905},
	abstract = {The falsification of faces in videos is a growing phenomenon over the years. One of the most popular ways to tamper a face in a video is known as ”deepfake”. Today, many tools exist to allow anyone to create a deepfake to discredit an individual or usurp an identity. Fortunately, the detection of deepfakes is an increasing topic of interest for the scientific community. As a result, many efforts have been made to develop mechanisms to automatically identify deepfake videos. In addition, several public deepfakes datasets have been built to help researchers to develop more effective detection methods. The most recent and also the most complete of these datasets is the one built by Facebook as part of the international DeepFake Detection Challenge (DFDC). Thousands of different frameworks, mainly based on deep learning, have been proposed during this challenge. The best solution that has been proposed obtains the accuracy of 82\% on the DFDC dataset. However, the accuracy of this method is only 65\% on unseen videos from the Internet. In this paper we analyse the five best methods of the DFDC and their complementarity. In addition, we experimented different assembly strategies (boosting, bagging and stacking) among these solutions. We show that we can achieve a large improvement (+41\% on log loss and +2.26\% on accuracy) when we carefully choose the models to be assembled with the most appropriate right merging method to use.},
	language = {en},
	urldate = {2025-07-09},
	booktitle = {2022 30th {European} {Signal} {Processing} {Conference} ({EUSIPCO})},
	publisher = {IEEE},
	author = {Trabelsi, Anis and Pic, Marc Michel and Dugelay, Jean-Luc},
	month = aug,
	year = {2022},
	pages = {643--647},
	file = {PDF:files/115/Trabelsi et al. - 2022 - Improving Deepfake Detection by Mixing Top Solutions of the DFDC.pdf:application/pdf},
}

@article{xia_deepfake_2022,
	title = {Deepfake {Video} {Detection} {Based} on {MesoNet} with {Preprocessing} {Module}},
	volume = {14},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2073-8994},
	url = {https://www.mdpi.com/2073-8994/14/5/939},
	doi = {10.3390/sym14050939},
	abstract = {With the development of computer hardware and deep learning, face manipulation videos represented by Deepfake have been widely spread on social media. From the perspective of symmetry, many forensics methods have been raised, while most detection performance might drop under compression attacks. To solve this robustness issue, this paper proposes a Deepfake video detection method based on MesoNet with preprocessing module. First, the preprocessing module is established to preprocess the cropped face images, which increases the discrimination among multi-color channels. Next, the preprocessed images are fed into the classic MesoNet. The detection performance of proposed method is veriﬁed on two datasets; the AUC on FaceForensics++ can reach 0.974, and it can reach 0.943 on Celeb-DF which is better than the current methods. More importantly, even in the case of heavy compression, the detection rate can still be more than 88\%.},
	language = {en},
	number = {5},
	urldate = {2025-07-09},
	journal = {Symmetry},
	author = {Xia, Zhiming and Qiao, Tong and Xu, Ming and Wu, Xiaoshuai and Han, Li and Chen, Yunzhi},
	month = may,
	year = {2022},
	note = {Publisher: MDPI AG},
	pages = {939},
	file = {PDF:files/118/Xia et al. - 2022 - Deepfake Video Detection Based on MesoNet with Preprocessing Module.pdf:application/pdf},
}

@misc{cao_understanding_2021,
	title = {Understanding the {Security} of {Deepfake} {Detection}},
	url = {http://arxiv.org/abs/2107.02045},
	doi = {10.48550/arXiv.2107.02045},
	abstract = {Deepfakes pose growing challenges to the trust of information on the Internet. Thus, detecting deepfakes has attracted increasing attentions from both academia and industry. State-of-the-art deepfake detection methods consist of two key components, i.e., face extractor and face classifier, which extract the face region in an image and classify it to be real/fake, respectively. Existing studies mainly focused on improving the detection performance in non-adversarial settings, leaving security of deepfake detection in adversarial settings largely unexplored. In this work, we aim to bridge the gap. In particular, we perform a systematic measurement study to understand the security of the state-of-the-art deepfake detection methods in adversarial settings. We use two large-scale public deepfakes data sources including FaceForensics++ and Facebook Deepfake Detection Challenge, where the deepfakes are fake face images; and we train state-of-the-art deepfake detection methods. These detection methods can achieve 0.94–0.99 accuracies in non-adversarial settings on these datasets. However, our measurement results uncover multiple security limitations of the deepfake detection methods in adversarial settings. First, we find that an attacker can evade a face extractor, i.e., the face extractor fails to extract the correct face regions, via adding small Gaussian noise to its deepfake images. Second, we find that a face classifier trained using deepfakes generated by one method cannot detect deepfakes generated by another method, i.e., an attacker can evade detection via generating deepfakes using a new method. Third, we find that an attacker can leverage backdoor attacks developed by the adversarial machine learning community to evade a face classifier. Our results highlight that deepfake detection should consider the adversarial nature of the problem.},
	language = {en},
	urldate = {2025-07-09},
	publisher = {arXiv},
	author = {Cao, Xiaoyu and Gong, Neil Zhenqiang},
	month = oct,
	year = {2021},
	note = {arXiv:2107.02045 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Cryptography and Security},
	annote = {Comment: To appear in ICDF2C 2021},
	file = {PDF:files/123/Cao and Gong - 2021 - Understanding the Security of Deepfake Detection.pdf:application/pdf},
}

@misc{tolosana_deepfakes_2020,
	title = {{DeepFakes} and {Beyond}: {A} {Survey} of {Face} {Manipulation} and {Fake} {Detection}},
	shorttitle = {{DeepFakes} and {Beyond}},
	url = {http://arxiv.org/abs/2001.00179},
	doi = {10.48550/arXiv.2001.00179},
	abstract = {The free access to large-scale public databases, together with the fast progress of deep learning techniques, in particular Generative Adversarial Networks, have led to the generation of very realistic fake content with its corresponding implications towards society in this era of fake news.},
	language = {en},
	urldate = {2025-07-09},
	publisher = {arXiv},
	author = {Tolosana, Ruben and Vera-Rodriguez, Ruben and Fierrez, Julian and Morales, Aythami and Ortega-Garcia, Javier},
	month = jun,
	year = {2020},
	note = {arXiv:2001.00179 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Multimedia},
	file = {PDF:files/124/Tolosana et al. - 2020 - DeepFakes and Beyond A Survey of Face Manipulation and Fake Detection.pdf:application/pdf},
}

@misc{vaswani_attention_2023,
	title = {Attention {Is} {All} {You} {Need}},
	url = {http://arxiv.org/abs/1706.03762},
	doi = {10.48550/arXiv.1706.03762},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	language = {en},
	urldate = {2025-07-09},
	publisher = {arXiv},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	month = aug,
	year = {2023},
	note = {arXiv:1706.03762 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
	annote = {Comment: 15 pages, 5 figures},
	file = {PDF:files/126/Vaswani et al. - 2023 - Attention Is All You Need.pdf:application/pdf},
}

@article{lad_adversarial_2024,
	title = {Adversarial {Approaches} to {Deepfake} {Detection}: {A} {Theoretical} {Framework} for {Robust} {Defense}},
	volume = {6},
	copyright = {https://creativecommons.org/licenses/by/4.0},
	issn = {3006-4023},
	shorttitle = {Adversarial {Approaches} to {Deepfake} {Detection}},
	url = {https://ojs.boulibrary.com/index.php/JAIGS/article/view/225},
	doi = {10.60087/jaigs.v6i1.225},
	abstract = {The rapid improvements in capabilities of neural networks and generative adversarial networks (GANs) has given rise to extremely sophisticated deepfake technologies. This has made it very difficult to reliably recognize fake digital content. It has enabled the creation of highly convincing synthetic media which can be used in malicious ways in this era of user generated information and social media. Existing deepfake detection techniques are effective against early iterations of deepfakes but get increasingly vulnerable to more sophisticated deepfakes and adversarial attacks. In this paper we explore a novel approach to deepfake detection which uses a framework to integrate adversarial training to improve the robustness and accuracy of deepfake detection models.},
	language = {en},
	number = {1},
	urldate = {2025-07-09},
	journal = {JAIGS},
	author = {Lad, Sumit},
	month = sep,
	year = {2024},
	note = {Publisher: Open Knowledge},
	pages = {46--58},
	file = {PDF:files/156/Lad - 2024 - Adversarial Approaches to Deepfake Detection A Theoretical Framework for Robust Defense.pdf:application/pdf},
}

@article{al-dulaimi_hybrid_2024,
	title = {A {Hybrid} {CNN}-{LSTM} {Approach} for {Precision} {Deepfake} {Image} {Detection} {Based} on {Transfer} {Learning}},
	volume = {13},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2079-9292},
	url = {https://www.mdpi.com/2079-9292/13/9/1662},
	doi = {10.3390/electronics13091662},
	abstract = {The detection of deepfake images and videos is a critical concern in social communication due to the widespread utilization of deepfake techniques. The prevalence of these methods poses risks to trust and authenticity across various domains, emphasizing the importance of identifying fake faces for security and preventing socio-political issues. In the digital media era, deep learning outperforms traditional image processing methods in deepfake detection, underscoring its significance. This research introduces an innovative approach for detecting deepfake images by employing transfer learning in a hybrid architecture that combines convolutional neural networks (CNNs) and long short-term memory (LSTM). The hybrid CNN-LSTM model exhibits promise in combating deep fakes by merging the spatial awareness of CNNs with the temporal context understanding of LSTMs. Demonstrating effective performance on open-source datasets like “DFDC” and “Ciplab”, the proposed method achieves an impressive precision of 98.21\%, indicating its capability to accurately identify deepfake images with a limited false-positive rate. The model’s error rate is 0.26\%, emphasizing the challenges and intricacies inherent in deepfake detection tasks. These findings underscore the potential of hybrid deep learning techniques for addressing the urgent issue of deepfake image detection.},
	language = {en},
	number = {9},
	urldate = {2025-07-09},
	journal = {Electronics},
	author = {Al-Dulaimi, Omar Alfarouk Hadi Hasan and Kurnaz, Sefer},
	month = apr,
	year = {2024},
	note = {Publisher: MDPI AG},
	pages = {1662},
	file = {PDF:files/157/Al-Dulaimi and Kurnaz - 2024 - A Hybrid CNN-LSTM Approach for Precision Deepfake Image Detection Based on Transfer Learning.pdf:application/pdf},
}

@inproceedings{meng_deepfake_2024,
	title = {Deepfake {Detection} {Based} on {Multi}-scale {RGB}-{Frequency} {Feature} {Fusion}},
	doi = {10.1109/CIPCV61763.2024.00018},
	booktitle = {2024 2nd {International} {Conference} on {Intelligent} {Perception} and {Computer} {Vision} ({CIPCV})},
	author = {Meng, Yuan and Wang, Xiyuan and Wang, Xueqin and Liu, Ziliang and Zhou, Hao},
	year = {2024},
	keywords = {Adaptation models, CNN combined with ViT, Deepfake detection, Deepfakes, Feature extraction, Finance, Image coding, multi-scale feature extraction, Network architecture, Rgb-Frequency domain feature fusion, Transformers},
	pages = {46--50},
}
